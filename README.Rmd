---
title: "README"
author: "Gabri, Pablo, Joey"
date: "December 14, 2018"
output: 
  github_document:
    html_preview: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.path = "README-"
)
```

# fecScrape

The fecScrape package provides functions to interface with the [OpenFEC API](https://api.open.fec.gov/developers/). OpenFEC API allows you to access funding data on candidates and committees. This package allows users to scrape individual- and aggregated-level donation data, plot these data to examine the timecourse of donation as well as geographic spread of donations, and does some basic summary statistics. 

# Thanks

During this class project, we came across another package which inspired our own code and thoughts on how to develop this package. Please check out the [tidyusafec](https://github.com/stephenholzman/tidyusafec) package, written by Stephen Holzman. 

# Installation 

Installation is done locally for now. Make sure that the project is specified to fecScrape_project and that both libraries are installed. 

```{r, message = FALSE, warning = FALSE, eval = FALSE}
library(devtools)
library(roxygen2)
setwd("./fecScrape") # pathway for where the package folder is located
document() # knits? the package together for use
library(fecScrape)
```

# Functions

To Do: Create a naming schematic for the functions such that all functions which interface with the OpenFEC API use the "query_" prefix and all functions which plot data use the "plot_" prefix. 

  [x] choose_cand
  [x] query_contributions_all
  [x] query_itemized_contributions
  [x] plot_donations
  [x] query_candidate_list
  [x] query_openfec
  [x] plot_cities
  [x] plot_occupations

# Example: 2018 Senate race between Whitehouse & Flanders

## Step 1: Scrape candidates running in an election of interest. 

For our example, we will focus on the recent 2018 Sentate race in West Virginia between Sheldon Whitehouse and Robert Flanders of Rhode Island. We wanted to choose Texas, since Beto and Cruz raised tens of millions of dollars, but the scraping takes a very long time!

```{r, message = FALSE, warning = FALSE, eval = FALSE}
# Find and select candidates
my_api <- "_______________________" # change to your api_key please!

ri_data <- query_candidate_list(
  api_key = my_api, 
  state = "RI", 
  election_year = 2018, 
  office = "S"
)
ri_data$name

# Select candidates of interest
ri_chosen_data <- choose_cand(ri_data, 3, 5) #numbers are optional, script will prompt for them, 3 specifies Flanders, #5 specifies Whitehouse
head(ri_chosen_data)

```

## Step 2: Find individual donations for specified candidates

```{r, message = FALSE, warning = FALSE, eval = FALSE}
# Find all individual donations to each candidates' primary committee
ri_indiv_data <- query_contributions_all(
  input_candlist = ri_chosen_data, 
  api_key = my_api
)
```

## Step 3: Plot average donations
```{r, message = FALSE, warning = FALSE, eval = FALSE}
ri_avg_donation <- plot_avg_donation(ri_indiv_data)
ri_avg_donation
```

## Step 4: Plot cummulative donations
```{r, message = FALSE, warning = FALSE, eval = FALSE}
ri_cum_donation <- plot_cum_donation(ri_indiv_data)
ri_cum_donation
```

## Step 5: Plot cities of donators 
```{r, message = FALSE, warning = FALSE, eval = FALSE}
ri_cities_donation <- plot_top_cities(3, ri_indiv_data)
ri_cities_donation
```

## Step 6: Plot occputations of donators 
```{r, message = FALSE, warning = FALSE, eval = FALSE}
ri_occup_donation <- plot_occupations(4, ri_indiv_data)
ri_occup_donation
```